
save-token.sh
-> für current conv
-> req evaluation
count-token -> als llm task außerhalb convers?





----

_active_conversations[(user_hash, channel)] -->  multiple ConversationManager instances per container

----




save conversation in "last chats" autom 


---
komplette conv hist zw fastapi und openai zu jeweiligen container loggen !! 
---






Port Mapping for ssh -> user can ssh into own container:
firewallöffnen
createuser script ändern: port + key -> beide keys auf own volume laden
dockercompose: custom port
list notwendig?




run_llm_call_as_subprocess.sh ändern: als output nur "ok" oder error message, api result
-> egal für script -> alles weg


Conversation evaluation: when to update req.md??


conversation turn counter -> gegen ende trim prompt inject
token counter



terraform ebs in userdata script




redis streams   -> ey  



GUI:
-text snippets markieren und mit Tags vershen + user comment dazu -> was sieht llm? wie gui comments?


