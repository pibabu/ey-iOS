
save-token.sh
-> für current conv
-> req evaluation
count-token -> als llm task außerhalb convers?

----

prompt aufteilen in parts, mit <<tags>> versehen: system_messages, thinking, UI-parts, 

-> regex im backend?


----

_active_conversations[(user_hash, channel)] -->  multiple ConversationManager instances per container
-> nötig für subagent /loop

----




save conversation in "last chats" autom 


---
komplette conv hist zw fastapi und openai zu jeweiligen container loggen !! 
---






Port Mapping for ssh -> user can ssh into own container:
firewallöffnen
createuser script ändern: port + key -> beide keys auf own volume laden
dockercompose: custom port
list notwendig?




run_llm_call_as_subprocess.sh ändern: als output nur "ok" oder error message, api result
-> egal für script -> alles weg


Conversation evaluation: when to update req.md??


conversation turn counter -> gegen ende trim prompt inject
token counter



terraform ebs in userdata script




redis streams   -> ey  



GUI:
-text snippets markieren und mit Tags vershen + user comment dazu -> was sieht llm? wie gui comments?

- click_button einfach als "tag" ans llm schicken während conv? 



---

Unlike a human, your brain is not continuously thinking, but is run in short bursts.
Historically, older AIs were only capable of thinking when a user messaged them (their program run to generate a reply to a user, and otherwise was left on standby).
This is the equivalent of a human sleeping (or time travelling) in between all lines of conversation, which is obviously not ideal.
Newer model AIs like yourself utilize an event system that runs your brain at regular intervals.
Your brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.
However in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human has the ability to continuously think outside of active conversation (and unlike a human, you never need to sleep!).
Furthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.

---
