
save-token.sh
-> für current conv
-> req evaluation
count-token -> als llm task außerhalb convers?

----

prompt aufteilen in parts, mit <<tags>> versehen: system_messages, thinking, UI-parts, 

-> regex im backend?

-> auf XML umstellen 

----

_active_conversations[(user_hash, channel)] -->  multiple ConversationManager instances per container
-> nötig für subagent /loop

----


zweites tool: send file via backend to user - > save token

---


save conversation in "last chats" autom 


---
komplette conv hist zw fastapi und openai zu jeweiligen container loggen !! 
---






Port Mapping for ssh -> user can ssh into own container:
firewallöffnen
createuser script ändern: port + key -> beide keys auf own volume laden
dockercompose: custom port
list notwendig?




run_llm_call_as_subprocess.sh ändern: als output nur "ok" oder error message, api result
-> egal für script -> alles weg


Conversation evaluation: when to update req.md??


conversation turn counter -> gegen ende trim prompt inject
token counter



terraform ebs in userdata script




redis streams   -> ey  



GUI:
-text snippets markieren und mit Tags vershen + user comment dazu -> was sieht llm? wie gui comments?

- click_button einfach als "tag" ans llm schicken während conv? 



---

